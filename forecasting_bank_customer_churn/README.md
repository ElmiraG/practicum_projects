# Прогнозирование оттока клиентов Бета-Банка
Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. 

Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.

Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.

Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)

# Описание данных
**Файл:** /datasets/Churn.csv

**Признаки:**


RowNumber — индекс строки в данных

CustomerId — уникальный идентификатор клиента

Surname — фамилия

CreditScore — кредитный рейтинг

Geography — страна проживания

Gender — пол

Age — возраст

Tenure — сколько лет человек является клиентом банка

Balance — баланс на счёте

NumOfProducts — количество продуктов банка, используемых клиентом

HasCrCard — наличие кредитной карты

IsActiveMember — активность клиента

EstimatedSalary — предполагаемая зарплата


**Целевой признак:**

Exited — факт ухода клиента

# План по выполнению проекта
1. Загрузить и подготовить данные.

2. Исследовать баланс классов, обучить модель без учёта дисбаланса.

3. Улучшить качество модели, учитывая дисбаланс классов. Обучить разные модели и найти лучшую.

4. Провести финальное тестирование.

## Общий вывод 

**1. Данные проанализированы и предобработаны:**

- Заменены прописные буквы в названиях столбцов на строчные и подправлены некоторые названия для корректности.
- В столбце 'Tenure' заполнены пропуски в данных. Тип данных изменен на integer.
- Категориальные столбцы 'Geography' и 'Gender' преобразованы.
- В столбцах 'HasCrCard', 'IsActiveMember' замен тип данных на bool.

**2. Задача исследована:**

- Проведена проверка на мультиколлинеарность признаков.
- Метрика f1 при предварительном исследование выше у модели RandomForest и равна 0.65. 
- Метрика f1 модели DecisionTree равна 0.58.
- Метрика f1 модели LogisticRegression равна 0.53.
- На метрику f1 моделей DecisionTree и RandomForest не повлияло масштабирование признаков, так как данные алгоритмы требуют разбиение на разделы.
- Масштабирование признаков не повлияло на значение метрики f1 модели LR.
- Дисбаланс классов 1:4.

**3. Улучшен баланс классов:**

Были использованы две техники балансирования классов Undersampling и Oversamping.

  - Методы Undersampling: 
    - функция Downsampling.
    - RandomUnderSampler() библиотеки imblearn.
    - K-Means, ClusterCentroids() библиотеки imblearn.
    
  - Методы Oversamping: 
     - функция Upsampling.
     - RandomOverSampler c shrinkage библиотеки imblearn
     - SMOTE()  библиотеки imblearn

Максимальное значение метрики f1 достигла модель RandomForest с применением Tomek Links() библиотеки imblearn (метод  Oversamping), f1=0.66,  см. п. 3.4.2. 

**4. Модели протестированы на тестовой выборке:** 

- Модель RandomForest показала значения на тестовой выборке по метрке f1=0.60.

- В сравнении с изначальной моделью RF без масштабирования: 
   - Метрика f1 уменьшилась с 0.66 до 0.60.
   - Количество истинно отрицательных ответов не изменилось. 
   - Количество истинно положительных ответов уменьшилось с 0.14 до 0.13.
   - Количество ложно отрицательных предсказаний (клиент остался) увеличилось с 0.061 до 0.077.
   - Количество ложно положительных предсказаний (клиент ушел) увеличилось с 0.092 до 0.093. 
   - Метрика accuracy уменьшилась с 0.85 до 0.83.
   - Метрика precision уменьшилась с 0.61 до 0.58.
   - Метрика recall уменьшилась с 0.70 до 0.62.
   - Значение AUC уменьшилась с 0.87 до 0.85.

- Модель прошла через машстабирование признаков StandartScaler()
- Гиперпараметры итоговой модели RandomForest: 
   - f1 = 0.65, 
   - class_weight = 'balanced',
   - criterion = 'entropy',
   - max_depth = 10,
   - n_estimators = 50
