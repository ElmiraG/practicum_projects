# Предсказание музыкального жанра
**Описание проекта**
Допустим, я сотрудник Отдела Data Science популярного музыкального стримингового сервиса "МиФаСоль". Сервис расширяет работу с новыми артистами и музыкантами, в связи с чем возникла задача - правильно классифицировать новые музыкальные треки, чтобы улучшить работу рекомендательной системы. Ваши коллеги из отдела работы со звуком подготовили датасет, в котором собраны некоторые характеристики музыкальных произведений и их жанры. Задача - разработать модель, позволяющую классифицировать музыкальные произведения по жанрам.
# План по выполнению проекта
1. Загрузка данных
2. Предобработка и исследовательский анализ данных
3. Разработка новых синтетических признаков
4. Проверка на мультиколлинеарность
5. Отбор финального набора обучающих признаков
6. Выбор и обучение моделей
7. Итоговая оценка качества предсказания лучшей модели
8. Анализ важности признаков
9. Отчет по исследованию
# Описание данных
**Данные:**

- **train.csv** - информация (~20000) музыкальных треках, которые будут использоваться в качестве обучающих данных.
- **test.csv** - информация (~5000) музыкальных треках, которые будут использоваться в качестве тестовых данных. Ваша задача - предсказать значение 'music_genre' для каждого трека из этого датасета.
- **sample_submit.csv** - файл предсказаний в правильном формате.

- instance_id - идентификатор трека в тестовом наборе.
- music_genre - Целевой признак. Для каждого трека предскажите категориальное значение соответствующее музыкальному жанру трека.

**Описание полей данных:**

- **instance_id** -Уникальный идентификатор трека
- **track_name** - Название трека
- **acousticness** - Мера уверенности от 0,0 до 1,0 в том, что трек является акустическим. 1,0 означает высокую степень уверенности в том, что трек является акустическим.
- **danceability** - Танцевальность описывает, насколько трек подходит для танцев, основываясь на сочетании музыкальных элементов, включая темп, стабильность ритма, силу ударов и общую регулярность. Значение 0,0 означает наименьшую танцевальность, а 1,0 - наибольшую танцевальность.
- **duration_ms** - Продолжительность трека в миллисекундах.
- **energy** - Энергия это показатель от 0,0 до 1,0, представляющий собой меру интенсивности и активности. Как правило, энергичные композиции ощущаются как быстрые, громкие и шумные. Например, дэт-метал обладает высокой энергией, в то время как прелюдия Баха имеет низкую оценку этого параметра
- **instrumentalness** - Определяет, содержит ли трек вокал. Звуки "Ooh" и "aah" в данном контексте рассматриваются как инструментальные. Рэп или разговорные треки явно являются "вокальными". Чем ближе значение инструментальности к 1,0, тем больше вероятность того, что трек не содержит вокала
- **key** - базовый ключ (нота) произведения
- **liveness** - Определяет присутствие аудитории в записи. Более высокие значения liveness означают увеличение вероятности того, что трек был исполнен вживую. Значение выше 0,8 обеспечивает высокую вероятность того, что трек исполняется вживую
- **loudness** - Общая громкость трека в децибелах (дБ)
- **mode** - Указывает на модальность (мажорную или минорную) трека
- **speechiness** - Речевой характер определяет наличие в треке разговорной речи. Чем более исключительно речевой характер носит запись (например, ток-шоу, аудиокнига, поэзия), тем ближе значение атрибута к 1,0. Значения выше 0,66 характеризуют треки, которые, вероятно, полностью состоят из разговорной речи. Значения от 0,33 до 0,66 характеризуют треки, которые могут содержать как музыку, так и речь, как в виде фрагментов, так и в виде слоев, включая такие случаи, как рэп-музыка. Значения ниже 0,33, скорее всего, представляют музыку и другие неречевые треки.
- **tempo** - Темп трека в ударах в минуту (BPM). В музыкальной терминологии темп представляет собой скорость или темп данного произведения и напрямую зависит от средней продолжительности тактов
- **obtained_date** - дата загрузки в сервис
- **valence** - Показатель от 0,0 до 1,0, характеризующий музыкальный позитив, передаваемый треком. Композиции с высокой валентностью звучат более позитивно (например, радостно, весело, эйфорично), а композиции с низкой валентностью - более негативно (например, грустно, депрессивно, сердито)
- **music_genre** - Музыкальный жанр трека


## 9. Отчет по исследованию

**Предобработка данных:**
1. Удалены столбцы с id и датой загрузки, в них нет надобности для построения модели машинного обучения. После удаление столбцов была проведена проверка на наличие дубликатов, так как их сохранение может привезти к переобучению моделей

2. В двух выборках есть пропуски в одних и тех же столбцах: key, mode, tempo (от 2-4% всех данных). Заполнение пропусков в признаке tempo, key и mode будет происходить на этапе создания моделей ML с помощью pipline.

3. Неявные дубликаты в категориальных данных отсутствуют

4. Аномалии:
В признаке duration_ms аномальная продолжительность треков (значение -1) составляет около 10% в каждой выборке. Связь между аномалиями и жанрами треков не найдена. Аномальные значения заменены на nan, решение заполнить получившиеся пропуски на медиану в связке с коррелирующими признаками к целевой переменной - уменьшило итоговую метрику. Аномальные значения вернула к nan.

**Исследование данных:**

1. Целевой признак music_genre

*  Жанры в выборке распределены не равномерно, частота варьируется от 5,6 до 14.0%.
*  3 самых встречаемых жанра это: Blues (14,0%), Alternative (12,8%), Electronic (12,6%)
*  3 жанра с минимальной частотой - Hip-Hop (5.6%), Jazz (6.1%), Classical (6.7%)

2. Исследованна частота слов в названиях треков.

Чаще всего в названиях есть обозначение коллаборации с другим исполнителем (feet), указатель музыкального заимствования (remix) и переиздания (remaster). Поется о любви и женщинах. Есть и треки на японском языке.

3. Исследованна модальности треков.

- Большинство треков вне зависимости от жанра имеют мажорную модальность.
- Соотношение мажорной и минорной модельности по жанрам:
    - около 50/50 в Electronic, Hip-hop, Jazz и Rap
    - около 75/25 в Alternative, Classical, Anime
    - около 85/15 в Blues и Rock
    - около 90/10 в Country

4. Исследованн базовый ключ треков

Некоторые жанры имеют схожее распределение встречаемости базовых ключей:

* Blues и Country
* Alternative и Anime
* Electronic, Rap, Hip-Hop
* Rock и Classical
* Только в Jazz распределение ключей уникально

5. Исследованна громкость треков:

* Громкость треков распределена примерно одинаково в тренировочной и тестовой выборке.
* В жанре Classical, в основном, произведения с низкой громкостью, в Anime - высокой

6. Исследован речевой признак треков:

* Чаще всего музыка и речь одновременно встречается в жанре Rap, Hip-Hop и Electronic.
* Исключительно речь - в Rap и Alternative
* 95-96% признака составляют данные одной категории, этот признак решено удалить перед обучением модели, так как он неинформативен.

7. Исследована продолжительность треков:

* Высокая продолжительность трека встречается в среднем в 25% данных, низкая - 15%

* В жанре Jazz одинаково распространены треки со средней и высокой продолжительностью, в Classical - чаще встречаются треки с высокой, в Electronic треки с высокой продолжительностью встречаются примерно в 0,75 раз меньше, чем средней. В остальных жанрах распределение схоже.

8. Чаще всего треки, исполненные в живую, встречаются в жанре Blues, реже в Electronic и Country

8. Решено создать новый синтетический признак на базе признака track_name

**Созданы новые признаки**

**1. name_category**, включающий в себя ключевые слова из треков, всего 9 признаков:
- unknown - 80% всех треков, feat - 6%, love - 3%, remastered, woman, japanese, classical, remix - каждые по 2%.

* Категория feat часто встречается в  жанрах: Rap(17%), Hip-Hop(16.8%), Electronic (8.7%)
* Категория love: Blues(5.7%), Jazz(5.7%), Rock(5.7%), Country(5.6%)
* Категория life есть в жанрах: Blues(6.7%), Classical(5.2%)
* Категория remastered: Rock(7.8%), Blues(4.9%), Jazz(3.3%)
* Категория woman: Country(4.7%)
* Категория japanese: Anime(22%)
* Категория classical: Classical(51.8%)
* Категория dance: Electronic (9,6%)

2. Исходный признак, на основе которых создан синтетический - удален

**Проведена проверка на мультиколлинеарность с помощью библиотеки phick**

Проверка на мультиколлинеарность происходила в процессе работы, когда мною было решено заменить некоторые численные признаки на категориальные. Предоставленный результат относится к тому моменту работы, так как иначе phick больше не прогружался из-за больших вычислительных затрат.

Существует высокая корреляция (>0.6) между такими парами переменных как:

music_genre - energy (0.67)
music_genre - acousticness (0.66)
loudness - acousticness (0.62)
music_genre - danceability (0.62)
Признак tempo имеет высокую корреляцию с несколькими переменными:

liveness_category (0.8), duration_ms (0.62), loudness (0.73), speechiness (0.93), name_category (0.81), valence (0.81), key (0.81), instrumentalness (0.72), energy (0.89), danceability (0.87), acousticness (0.89)
Признак energy также имеет высокую корреляцию с несколькими переменными:

loudness (0.76), music_genre (0.67), acousticness (0.77)


Практически отсутствует корреляция (=0.01) между признаками:

liveness_category - loudness
mode - loudnes
mode - speechiness

**Для построения модели выбран алгоритм CatBoostClassifier c заданным random_state=12345.**

Создан  конвейер предобработки числовых признаков num_pipeline. Включает в себя следующие этапы:

- StandardScaler() - стандартизация числовых признаков.
- PolynomialFeatures() - создание полиномиальных признаков.
- DropCorrelatedFeatures(threshold=0.9) - удаление коррелирующих признаков с порогом корреляции 0.9.
- DropConstantFeatures(tol=0.998) - удаление постоянных признаков с порогом вариации 0.998.

Создан pipeline с помощью:

- преобразователя столбцов column_transformer,
- заполнением пропущенных значений в числовых данных с помощью IterativeImputer,
- балансировкой данных с помощью SMOTETomek (SMOTE позволяет сгенерировать синтетические примеры для класса меньшинства, тогда как Tomek link удаляет примеры, которые приводят к "текущему размещению")
- использованием заданной модели CatBoostClassifier.
- В переменной params указаны параметры для подбора оптимальных значений модели при помощи RandomizedSearchCV. Этот метод будет искать лучшие значения параметров, обучая и оценивая модель на разных комбинациях параметров.

После обучения модели выводятся лучшие найденные параметры и значение оценки F1-микро наилучшей модели.

**Итоговая оценка качества предсказания лучшей модели**

Параметры лучше модели:
- learning_rate = 0.1,
- iterations = 400,
- depth = 5

На валидационной выборке метрики:

Accuracy: 0.464
Micro Precision: 0.464
Micro Recall: 0.464
Micro F1-score: 0.464

Использование GridSearchCV поможет подобрать более точные метрики для лучшего предсказания модели

- Максимальное количество правильно классифицированных классов для жанров Rap, Electronic, Anime
**Анализ важности признаков**
Модель определяла жанр, в основном, по таким признакам как:
- instrumentalness(содержит ли трек вокал),
- speechiness(наличие в треке разговорной речи),
- dancebility(насколько трек подходит для танцев),
- acousticness(является ли трек акустический),
- loudness(громкость трека)

- наименьшее значение у признаков liveness(присутствие аудитории в записи) и mode(модальность трека)

