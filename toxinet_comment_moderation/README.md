# Токсинет: Модерация комментариев для Викишоп

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Необходимо обучить модель классифицировать комментарии на позитивные и негативные, используя набор данных с разметкой о токсичности правок.

Значение метрики качества *F1* должна быть не меньше 0.75. 

**План по выполнению проекта**

1. Загрузка и подготовка данных
2. Выбор и обучение моделей
3. Тестирование. Вывод

**Описание данных**

- `toxic_comments.csv`- ссылка на данные 
- Столбец *text* - текст комментария
- Столбец *toxic* — целевой признак

### Вывод
**При создание модели были проведены следущие шаги:**

1. Анализ и предобработка данных:
Процесс включал лемматизацию, удаление стоп-слов и анализ частотности слов. Классы оказались несбалансированными: количество нетоксичных комментариев в 9 раз превышает количество токсичных. Выявлено, что в токсичных комментариев много ругательств. Данные подготовлены к моделированию: разделены на тренировочные и тестовые наборы.

2. В проекте используются следующие модели:
   - Логистическая регрессия с параметром балансировки классов
   - Логистическая регрессия с применением RandomUnderSampler()

Подбор гиперпараметров осуществлялся с помощью GridSearchCV

**Лучашя модель LogisticRegression без применения RandomUnderSampler, с параметрами:**
- C = 10,
- class_weight='balanced',
- max_iter = 50
- solver = liblinear

3. Модель логистической регрессии, обученная с учетом баланса классов, показала смешанные результаты в задаче классификации токсичных комментариев. С одной стороны, F1-мера, составляющая на тренировочной выборке 0.78, и AUC-значение 0.97 свидетельствуют о достаточно высокой общей эффективности модели.

С другой стороны, модель демонстрирует низкую точность (72%), что означает, что значительная доля нетоксичных комментариев ошибочно классифицируется как токсичные. Это может привести к нежелательным последствиям, таким как неправомерная блокировка комментариев в социальных сетях или на форумах. Полнота модели достаточно высока (84%), что означает хорошую способность модели обнаруживать токсичные комментарии, но в ущерб точности.

Для практического применения такой модели важно найти баланс между минимизацией ложно положительных и ложно отрицательных результатов. Возможные шаги для улучшения включают в себя дальнейшую настройку гиперпараметров, использование других алгоритмов машинного обучения, которые могут лучше справляться с задачами с несбалансированными данными, или применение техник обработки текста для улучшения качества входных данных.
